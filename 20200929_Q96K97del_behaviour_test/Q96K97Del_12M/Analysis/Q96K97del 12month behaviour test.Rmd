---
title: "FMP Y-maze test of spatial working memory on Q96K97del/+ vs +/+ 12month fish"
author: "Yang & Karissa"
date: "15/10/2019"
output: 
  html_document: 
    toc: yes
    toc_float: yes
    code_folding: hide
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r packages}
library(tidyverse)
library(magrittr)
library(ggrepel)
library(readxl)
library(kableExtra)
library(lubridate)
library(ggpubr)

# Statistical analysis
library(car)
library(performance)
library(lmerTest)
library(lme4)
library(emmeans)
library(glmmTMB)
if (interactive()) setwd(here::here("Q96K97Del_12M","Analysis"))
```

## R Markdown

## Introduction & summary of raw data

The Free-movement pattern (FMP) Y-maze test involves placing a fish in a Y-shaped with three identical arms oriented at an angle of 120° relative to each other and filled with 1L of aquarium water. The movements of the fish are monitored during 1-hour free exploration. This data is recorded in a spreadsheet as the raw data with the times entering and exiting a zone of the Y maze. We perform this test blinded and genotype the fish after the data has been aquired as to not put them under any extra stress from the process of tail clipping. Zantiks have a script which allows us to batch process the raw data files into a *tibble* containing the frequencies of *tetragrams* (sequence of four consecutive arm entries). The script was performed in a different R script. 

```{r raw data treatment based using zantiks script}
# Set input and output to the correct paths in the directory
input = "../Original Data"
output = "../Output"

# IMPORT DATA -------------------------------------------------------------
setwd(input)
file_list <- list.files(pattern = "*.csv") #Create a list of files from ./data directory

df <- tibble(file_list = file_list) %>% #Import data as a tibble with nested lists
  mutate(tail = map(file_list, ~ read_csv(.x, col_names = F, skip = 4)), #tail = data
         head = map(file_list, ~ read_csv(.x, col_names = F, n_max = 4))) # head = demographic info

df[[3]] <- #Convert data nested in "head" into a usable format
  df[[3]] %>% 
  map(~ spread(.x, X3, X4)) %>% 
  map(~ separate(.x,"Subject Identification", c("fish1", "fish2"))) %>% 
  map(~ select(.x, X1,X2, "Apparatus", "fish1","fish2", "Unit ID"))

df[[2]] <- df[[2]] %>% map(~ mutate(.x, X4 = as.character(X4))) # ensure that "X4" is character because unnest() can't handle mixed data types in list

df <- #convert df from a tibble w/ nested lists to a basic tibble
  df %>% 
  unnest(head) %>% 
  unnest(tail)

# DATA WANGLING -----------------------------------------------------------
## STEP 1 - select variables that we are intrested in
df<-
  df %>% 
  select(file_list, Apparatus, `Unit ID`,X11, X4, X5, X6, fish1, fish2) %>% #select the vars we're intrested in
  rename(file_id = file_list, #renames vars
         apparatus = Apparatus,
         unit_id = `Unit ID`,
         time = X11,
         arena = X4)

## STEP 2 - convert to tidy data
df <- na.omit(df) #remove na values
df$time <- hms(df$time) #fixing time varible

df <-
  df %>% 
  mutate(i = row_number()) %>% 
  spread(X5, X6) %>% #create separate columns for "Enter_Zone" and "Exit_Zone"
  rename(enter_zone = Enter_Zone, exit_zone = Exit_Zone)

## STEP 3 - create "fish_id" column and arrange in chronological order
df <- 
  df %>% 
  mutate(fish_id = ifelse(arena == 1, fish1,
                   ifelse(arena == 2, fish2,
                          NA))) %>% 
  select(file_id, apparatus, unit_id, time, arena, fish_id, enter_zone, exit_zone)

## STEP 4 - export for backup/later use
setwd(output)
write.csv(df, "tidy_data.csv")

# ANALYSIS ----------------------------------------------------------------
df_a <- df #create a new tibble to analyse

## STEP 1 - create 10 min bins 
df_a <-
  df_a %>% 
  mutate(elapsed_secs = seconds(df_a$time)) %>%  #create an elapse_seconds column to bin from
  mutate(bin = ifelse(elapsed_secs >0 & elapsed_secs <600, 1,     #bin1
               ifelse(elapsed_secs >600 & elapsed_secs <1200, 2,  #bin2
               ifelse(elapsed_secs >1200 & elapsed_secs <1800, 3, #bin3
               ifelse(elapsed_secs >1800 & elapsed_secs <2400, 4, #bin4
               ifelse(elapsed_secs >2400 & elapsed_secs <3000, 5, #bin5
               ifelse(elapsed_secs >3000 & elapsed_secs <6000, 6, #bin6
                      NA)))))))                                   #NA

## STEP 2 - Prepare data ready to figure out which way the fish turned
df_a$time <- as.numeric(df_a$time) #time variables are not compatible with ddplr
df_a$elapsed_secs <- as.numeric(df_a$elapsed_secs)
df_a <- df_a %>% arrange(file_id,fish_id,elapsed_secs, exit_zone)  # order by fish_id and tie break by elepsed_secs
                                                                   # and then exit_zone so line 1 = enter, line 2 = exit
#Create new variables ready to make new data tibble
df_a <- df_a %>% 
  mutate(zone = ifelse(enter_zone == lead(exit_zone), enter_zone, 999)) %>% 
  mutate(time_enter = ifelse(enter_zone >= 1, elapsed_secs, 999)) %>% 
  mutate(time_exit = ifelse(exit_zone >= 1, elapsed_secs, 999))

#ERROR CHECK - if any rows == 999 then something has gone wronge with the previous line of code.
df_a %>% filter(zone == 999) 
df_a %>% filter(time_enter == 999)
df_a %>% filter(time_enter == 999)

#Wrangle data to figure out which way the fish turned
df_a <- df_a %>% select(file_id, apparatus, unit_id, arena, fish_id, bin, zone, time_enter, time_exit) %>% 
  mutate(time_exit = lead(time_exit)) #create one row per zone

df_a <- df_a %>% na.omit() #remove empty/pointless rows
df_a <- df_a %>% mutate(time_in_zone = time_exit - time_enter) #calculate time spent in each zone

## STEP 3 - Export for backup/later use 
setwd(output)
write.csv(df_a, "time_in_zone.csv")

##STEP 4 - Which way did the fish turn?
df_list <- df_a %>% filter(zone != 4) #remove centre zone (i.e. zone 4)
split_tibble <- function(tibble, col = "col") tibble %>% split(., .[,col]) #function to split tibble into list
df_list <- split_tibble(df_list, "fish_id") #split tibble into list

df_list <- df_list %>% 
  map(~ mutate(.x, lag_zone = lag(zone))) %>% #calculate direction turned for each fish
  map(~ mutate(.x, turn=case_when(lag_zone==1 & zone==2 ~ 'L',
                                  lag_zone==1 & zone==3 ~ 'R',
                                  lag_zone==2 & zone==1 ~ 'R',
                                  lag_zone==2 & zone==3 ~ 'L',
                                  lag_zone==3 & zone==1 ~ 'L',
                                  lag_zone==3 & zone==2 ~ 'R',
                                  TRUE~ NA_character_ ))) %>% 
  map(~ select(.x, file_id, apparatus, unit_id, arena, fish_id, bin, zone, turn)) #select rows that we are intrested in

df_b <- bind_rows(df_list) #merge list into single dataframe
df_b <- df_b %>% 
  arrange(file_id, fish_id, bin) %>% #restore previous order(i.e. by fish_id)
  na.omit() #remove NA rows

## STEP 5 - Tetragrams
df_c <- df_b %>% 
  group_by(fish_id, bin) %>% #create groups for tetragrams
  select(-arena, -zone) #remove arena and zone columns as they are no longer needed

df_c <- df_c %>% 
  mutate(tetragrams = str_c(turn, #create tetragrams column
                            lead(turn),
                            lead(turn,2),
                            lead(turn,3))) %>% 
  ungroup() %>% 
  select(fish_id, bin, turn, tetragrams) #delete unnecessary columns


## STEP 6 - Summarise
unique_tetragrams <- unique(df_c$tetragrams)
## Tetragrams
tet_long <- df_c %>% 
  select(-turn) %>% 
  na.omit() %>% 
  group_by(fish_id, bin) %>% 
  table() %>% 
  as.tibble() %>% 
  arrange(fish_id, bin) 

tet_wide <- tet_long %>% spread(tetragrams, n)

## Turns
turn_long <- df_c %>% 
  select(-tetragrams) %>% 
  na.omit() %>% 
  group_by(fish_id, bin) %>% 
  table() %>% 
  as.tibble() %>% 
  arrange(fish_id, bin) 

turn_wide <- turn_long %>% spread(turn, n)

## Final tibble
final_data <- tet_wide %>% 
  left_join(turn_wide, by = c("fish_id","bin")) %>% 
  mutate(total_turns = L + R,
         reps = LLLL + RRRR,
         alts = RLRL + LRLR,
         rel_reps = (reps*100)/total_turns,
         rel_alts = (alts*100)/total_turns,
         rel_R = (R*100)/total_turns,
         rel_L = (L*100)/total_turns)

## STEP 7 - Final Output
setwd(output)
write.csv(final_data, "final_output.csv")

#Read in the file which has the info about the fish 
meta <- read_xlsx("../Q96K97Del12Minformation.xlsx") %>% 
  dplyr::rename(fish_id = fish_id) %>% 
  mutate(fish_id = as.factor(fish_id), 
         Genotype = factor(Genotype, levels = c("WT", "Q96K97del/+"))
         ) 

# Make the final tibble with the data & metadata in 1 object
final_data %<>% 
  left_join(meta)
```


The output of the Zantiks script is shown below. It shows the frequencies of tetragrams for each fish over a series of *bins* (10 minute blocks). There are 6 bins per fish (as the data was collected over 1 hour). The totals are also shown in the final column.


```{r pressure, echo=FALSE}
final_data %>% 
  kable(align = 'c' ) %>% 
  kable_styling( latex_options = "basic") %>% 
  scroll_box(height = "400px")
```

## Data description
The Free-movement pattern (FMP) Y-maze test designed by Cleal et al., 2020 investigates animals’ search strategies by recording direction choices (left, L, or right, R) during an hour of free exploration. Impacts on working memory can be assessed by quantifying differences in “alternation tetragrams” (LRLR and RLRL), which are the dominant search strategy used in vertebrates.

In the FMP Y-Maze  task, fish are placed in the maze for 1 hour free exploration. The times in which the fish enters and exits the zones are recorded and this data is then processed by a script availbale on the Zantiks website to produce a data frame which contains frequencies of *tetragrams* (4 consecutive turns of left or right when entering the middle of the maze). The distribution of the frequencies of the 16 possible tetragrams is shown in the figure below. 

```{r}

#Calculate the total movement patterns over the hour
summedmovementpatterns <- final_data %>% 
  gather(key = "tetras", value = "Count", (3:18)) %>% 
  group_by(fish_id, tetras) %>% 
  summarize(total_turns = sum(Count)) 

# Plot the tetragram frequencies
final_data %>% 
  gather(key = "tetras", value = "Count",
         grep(pattern = "^[LR]{4}", colnames(.))) %>% 
  group_by(fish_id, tetras) %>% 
  summarize(totalperTetra = sum(Count)) %>% # sum the tetragram frequencies over the hour
  left_join(meta) %>% 
  ggplot(aes(tetras, totalperTetra, fill = Genotype)) +
  geom_boxplot(outlier.shape = NA) +
  geom_point(aes(shape = Genotype)) +
  scale_fill_manual(values = c("#00aaff", "#ff9d00")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
```

The plot above shows the counts of each tetragram over the total hour search period. A higher frenquency of alternation tetragrams are shown in both wild type and mutant zebrafish.

The hour is then divided up into 10 minute bins (The figure below). No obvious difference can be identified between each bin.


```{r}
final_data %>% 
  gather(key = 'tetras', value = 'count', grep("[L|R]{4}", colnames(.))) %>% 
  left_join(meta) %>%  
  dplyr::distinct(rel_alts, .keep_all = T) %>% 
  ggplot(aes(x = Genotype, y = rel_alts, fill = Genotype)) +
  geom_boxplot(outlier.shape = NA) +
  geom_jitter(aes(shape = Gender)) +
  facet_wrap(~bin, nrow = 1) +
  ylab("Relative alterations") +
  scale_fill_manual(values = c("#00aaff", '#ff9d00')) +
  theme_bw() 
```

## Generalised linear model
Here, it is expeted to be tested that whether heterozygosity for the Q96K97Del mutation in *psen1* has an effect on spatial working memory (i.e. alternatuion frequency). Previously, Karissa have tried using linear mixed effect models to determine whether the mutation affects the alternarion frequency. However, the data is not normally distributed so that a generalised linear model (GLM) is used here, which allows for the data to not be normally distributed.


For the GLM, both fixed and random effects are included:
Fixed effects:
 - Genotype (effect of interest) \n
 - Gender (Male biased so probably can omit from the model)
 - Time (Start time of the hour the fish spent in the Y maze)
 - bin (which 10 minute block over the hour spent in the maze)


Random effects:
- Day (Since we only have 2 mazes, had to collect the data over 11 days)
- fish_id (to account for one fish being measured in each bin)
- Day:Time interaction term



```{r}
glm1 <- final_data %>%
    mutate(non_alts = total_turns - alts,
           Day = paste0("Day", Day),
           fish_id = paste0("fish", fish_id),
           bin = factor(bin),
           dayTime = interaction(Day, Time, drop = TRUE)) %>% # manually create this interaction term to account for different responses at different days and times
    glmer(
        cbind(alts, non_alts) ~ (bin + Genotype)^2 + Time + (1|Day) + (1|fish_id) + (1|dayTime), 
        family = 'binomial',
        data = .
    )


Anova(glm1)
# check_overdispersion(glm1) # want a disperson ratio close to 1. 

```

The binomial data model above shows the data is overdispersed (extra-binomial variation that needs to be accounted for). One way to deal with this is fitting an observation-level, random-effect model, so we fit this below. However, this approach overcompensates for the extra variation such that the variance is under-dispersed (dispersion parameter closer to zero)

```{r}
glm1o <- final_data %>%
    mutate(non_alts = total_turns - alts,
           Day = paste0("Day", Day),
           fish_id = paste0("fish", fish_id),
           dayTime = interaction(Day, Time, drop = TRUE),
           bin = factor(bin),
           obs = 1:nrow(final_data)) %>% 
    glmer(
        cbind(alts, non_alts) ~ (bin + Genotype)^2 + Time + (1|Day) + (1|fish_id) + (1|dayTime) + (1|obs), 
        family = 'binomial',
        data = .
    )
summary(glm1o)
Anova(glm1o)
# check_overdispersion(glm1o)
```

Another way to account for the extra dispersion is to use a beta-binomial variance function, where the extra variation is modelled by an overdispersion parameter that is associated with the the varying sample sizes among observations.

For this approach, the extra parameter accounts for the overdispersion, so we don't then check for overdispersion.

I have fit the beta-binomial GLMM using the glmmTMB package.

```{r}

glm2 <- final_data %>%
    mutate(
      non_alts = total_turns - alts,
      Day = paste0("Day", Day),
      fish_id = paste0("fish", fish_id),
      dayTime = interaction(Day, Time, drop = TRUE),
      bin = factor(bin)
      ) %>% 
    glmmTMB(
        cbind(alts, non_alts) ~ (bin + Genotype)^2 + Time + (1|Day) + (1|fish_id) + (1|dayTime), 
        family = betabinomial(),
        data = .
    )
summary(glm2)
Anova(glm2)
```

In the model above, none of factors including genotype shows statistical significance.

```{r}
# Can get estimated means predicted from the model using the following code. Outputs from these can be saved into a data frame and plotted using ggplot

#' Time
print(emmeans(glm2, specs = "Time"),type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(Time, prob)) +
  geom_point() +
  theme_bw()

#' bin
contrast(emmeans(glm2, specs = "bin"), method = "trt.vs.ctrl1")

#' Genotype
print(emmeans(glm2, specs = "Genotype"),type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(Genotype, prob, colour = Genotype)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL))

#' Bin * Genotype
print(emmeans(glm2, specs = "bin", by = "Genotype"), type = "response") %>% 
  as_tibble() %>% 
  ggplot(aes(bin, prob, colour = Genotype)) +
  geom_point(size = 2) +
  geom_errorbar(
    aes(ymin = lower.CL, ymax = upper.CL), 
    width = 0.5
    ) +
  theme_bw() +
  ylab("Estimated mean altenations (LRLR and RLRL) from model")

```


